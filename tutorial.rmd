---
title: "3 Steps To Become A Data Scientist"
author: "Priyanka Kishore & Alisha Varma"
date: "5/17/2020"
output: rmdformats::readthedown
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Introduction
So you want to be a Data Scientist and don’t know where to start? Well, you’ve come to the right place. 

Today you’ll learn a little about the economy, a whole bunch of data science principles and practice and where to stay on your next trip to New York City!


## Data Science Pipeline
First, let’s look at the data science pipeline. 

The data science pipeline starts with defining what major questions one wants to answer and subsequently **_acquiring and importing the relevant data_** to be analyzed.

Then, the data is viewed and **_data tidying_** must occur; where a rectangular data structure model is assumed and three requirements must be met. Each observation (called an entity) forms a row, each variable (called an attribute) forms a column and each observational unit (type of entity) forms a table.

Leading to the exploratory data analysis process, where the data is transformed and visualized. **_Data cleaning_** may be necessary for missing data. When handling missing data, the missing data may be removed, encoded or imputation (replace missing values with the mean of non-missing values) of a numeric variable may be necessary.

Hypothesis testing and machine learning (ML) modeling are the final steps before the data and its results can be communicated.

![Image of Pipeline](https://d33wubrfki0l68.cloudfront.net/795c039ba2520455d833b4034befc8cf360a70ba/558a5/diagrams/data-science-explore.png)

_Source:_ https://r4ds.had.co.nz/explore-intro.html

## Economy & Vacations
The rise of companies like Airbnb has given rise to The Sharing Economy. The sharing economy is a model defined as the facilitation of goods and services on a peer-to-peer level usually through online community platforms. This new model has made it possible for a great deal of people to gain another source of income and for you to have an affordable vacation.

As more sharing economy companies have opened, like Airbinb and Uber, the way we vacation has changed. This change has been documented and open data on it is available.


## DataSet Used
The data we will be using in this tutorial is [_New York City Airbnb Open Data_](http://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data/data) from Kaggle. We will use this data to look at the relationships between types of housing and location.


# Preparing Data

Download the [dataset](https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data?select=AB_NYC_2019.csv).

In this section, we will learn how to load in our dataset, view the data in our dataset, and clean it up so it's easy for us to work with.

First, let's load in the following libraries so we can use certain functions:
```{r, message=FALSE}
# for data wranging
library(tidyverse)
library(dplyr)
library(geosphere)
```

## Loading Data

CSV files are files that include data which are "comma-separated values", meaning that data values are literally separated by commas.

After we've downloaded our CSV file from Kaggle into our working directory, we can use the `read_csv` function to load the CSV file data into our program's data frame, which is a table of the data.

```{r, message=FALSE}
# create a dataframe from our CSV file
airbnb_tab <- read.csv("AB_NYC_2019.csv", header=TRUE)
```

There are some attributes that we don't need for our purposes, like `host_id`, `host_name`, `minimum_nights`, `number_of_reviews`, `last_review`, `reviews_per_month`, and `calculated_host_listings_count`. So, let's remove these from our data frame:

```{r}
# a vector called "to_remove" that has the names of the attributes we don't want
to_remove <- c('host_id', 
              'host_name', 
               'minimum_nights', 
               'number_of_reviews', 
               'last_review', 
               'reviews_per_month', 
               'calculated_host_listings_count')

# removing attributes from data frame using "to_remove"
airbnb_tab = airbnb_tab[ , !(names(airbnb_tab) %in% to_remove)]
```

## Viewing Data

Here, we see the first 10 rows in our dataset:

```{r}
knitr::kable(head(airbnb_tab, n=10)[, -2]) # omit `name` attribute for neatness
```
Some Notes:
* knitr::kable() is used to make the table "pretty" and easier to read
* head(df, n=10) is used to view the dataframe with a specific number of rows (head() is not always necessary, you can just list the data frame for it to render)
  * df is where the dataframe goes, in this case airbnb_tab
  * n= determines the number of rows visible, in this case 1

The following is a list of descriptions for the attributes of our data set:

Attribute | Description/Unit
------------ | -------------
`id` | Unique ID for each Airbnb listing
`name` | Name or description of the Airbnb listing
`neighbourhood_group` | Boroughs of New York (Manhattan, Brooklyn, Queens, Bronx, Staten Island)
`neighbourhood` | Neighborhoods of New York
`latitude` | Degrees of latitude, measures distance North and South from Equator
`longitude` | Degrees of longitude, measure distance East and West of Prime Meridian
`room_type` | Type of space offered (Entire home/apt, Private room, Shared room)
`price` | Price of listing, in US Dollars
`availability_365` | Number of days in a year when the listing is available for booking


## Tidying Data

Tidying Data entails the elements listed in the list below.

Elements of a tidy dataset:
1. Each observation/entity forms a row
1. Each variable/attribute forms a column
1. Each observational unit (type of entity) forms a column (i.e. not dependent on one another)

Our dataset is already tidy and meets the criteria above. Each entity is a row and each attribute is a column, where no entity is dependent on another.

However, if your data set is untidy, below is an example on a different small dataset, to show you what to do.

### Sample Tidying



# Exploratory Data Analysis

In this section, we begin exploring what our data can tell us using *visualizations*. This will help us to better understand our data and help us make decisions about how we may want to further manipulate the data to see something specific, or decide which methods are best for modelling and Machine Learning!

The main reason for exploratory data analysis, or EDA, is to help us find any problems in our data preparation and gain a sense of variable properties, such as central trends (mean), spread (variance), skew, outliers, and relationships between pairs of variables, like their correlation or covariance.

You can read more about EDA at [CMSC 320 EDA Lecture Notes](https://www.hcbravo.org/IntroDataSci/bookdown-notes/exploratory-data-analysis-visualization.html) by Professor Hector Corrado Bravo.

## Handling Missing Data

Recall that the attribute `availability_365` tells us how many days in the year that this particular listing is available for people to book. 

Notice that 0 is a value for some of the entities (Airbnb listings). It doesn't make much sense for us to look at entities that aren't available at all during the year. In fact, more than 17000 entities are listed at being available for 0 days out of the year! That's about 1/3 of our dataset.

We'll call this "missing data", and remove these entities from our dataset:

```{r}

airbnb_tab <- airbnb_tab %>%
  filter(availability_365 > 0) # filter() is used to filter the dataframe via specific conditions

knitr::kable(head(airbnb_tab, n=10)[, -2]) # omit `name` attribute for neatness

```
Note that a way to handle missing data, as mentioned in the data science pipline section (data cleaning), is removing missing data togehter. Having 0 as a value for `availability_365` is form of missing data. 


## Visualizations


### Interactive Map

```{r}
library(leaflet)

# Creating NYC Map
nyc_map <- leaflet(airbnb_tab) %>%
  addTiles() %>%
  setView(
    lat=40.730610, 
    lng=-73.935242, 
    zoom=11)

nyc_map
```

```{r}
leaflet(airbnb_tab) %>% 
  addTiles() %>%
    addAwesomeMarkers(
      lng = ~longitude, 
      lat = ~latitude,
      icon = awesomeIcons(
              icon = 'ios-close',
              iconColor = 'black',
              library = 'ion',
              markerColor = ~ifelse(room_type == 'Entire home/apt', "green", 
                                    ifelse(room_type =='Private room', "orange", 
                                           "red"
                                    )
                            )
            ),
      
      ## Price Label
      label=~as.character(price),
    
      ## Clustering for identifying arrest density
      clusterOptions = markerClusterOptions()
    ) %>%
  addLegend(
    position = 'bottomright', 
    colors= c("green", "orange", "red"), labels=c("Entire Home/Apt", "Private Room", "Shared Room"), 
    title='Types of Rentals', 
  )
```



### Histograms
```{r, warning=FALSE}
library(ggplot2)
library(ggthemes)

airbnb_home <- airbnb_tab %>%
  filter(room_type == 'Entire home/apt')

knitr::kable(head(airbnb_home, n=10))
```


```{r}
airbnb_home %>%
  ggplot(aes(x = neighbourhood_group, y = price)) +
  geom_boxplot()+
  coord_flip() +
  theme_economist() + 
  scale_fill_economist() +
  labs(title = "Entire Homes & Appts. Price By Neighborhood in 2019",
       x = "Major Neighborhood Groups",
       y = "Price(USD)")
```


```{r, warning = FALSE}
airbnb_home %>%
  ggplot(aes(x = neighbourhood_group, y = price)) +
  geom_boxplot()+
  scale_y_continuous(limits = c(0, 1500)) +
  coord_flip() +
  theme_economist() + 
  scale_fill_economist() +
  labs(title = "2019 NYC Homes & Appts. Prices (Up to $1500/night)",
       x = "Major Neighborhood Groups",
       y = "Price(USD)")
```



```{r}
airbnb_room <- airbnb_tab %>%
  filter(room_type == 'Private room')

knitr::kable(head(airbnb_room, n=10))
```
```{r}
airbnb_room %>%
  ggplot(aes(x = neighbourhood_group, y = price)) +
  geom_boxplot()+
  coord_flip() +
  theme_economist() + 
  scale_fill_economist() +
  labs(title = "Private Room Price By Neighborhood in 2019",
       x = "Major Neighborhood Groups",
       y = "Price(USD)")
```

```{r, warning = FALSE}
airbnb_room %>%
  ggplot(aes(x = neighbourhood_group, y = price)) +
  geom_boxplot()+
  scale_y_continuous(limits = c(0, 500)) +
  coord_flip() +
  theme_economist() + 
  scale_fill_economist() +
  labs(title = "2019 NYC Private Room Prices (Up to $500/night)",
       x = "Major Neighborhood Groups",
       y = "Price(USD)")
```




```{r}
airbnb_sroom <- airbnb_tab %>%
  filter(room_type == 'Shared room')

knitr::kable(head(airbnb_sroom, n=10))
```


```{r}
airbnb_sroom %>%
  ggplot(aes(x = neighbourhood_group, y = price)) +
  geom_boxplot()+
  coord_flip() +
  theme_economist() + 
  scale_fill_economist() +
  labs(title = "Shared Room Price By Neighborhood in 2019",
       x = "Major Neighborhood Groups",
       y = "Price(USD)")
```

```{r, warning = FALSE}
airbnb_sroom %>%
  ggplot(aes(x = neighbourhood_group, y = price)) +
  geom_boxplot()+
  scale_y_continuous(limits = c(0, 200)) +
  coord_flip() +
  theme_economist() + 
  scale_fill_economist() +
  labs(title = "2019 NYC Shared Room Prices (Up to $200/night)",
       x = "Major Neighborhood Groups",
       y = "Price(USD)")
```


# Hypothesis Testing & Machine Learning

## Linear Regression


## ML Model




# Conclusion



# References
A thorough R-markdown guide https://bookdown.org/yihui/rmarkdown/
